{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oe7P_X7WVsJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0456db-74ff-4edd-8e43-1215befc763b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.5.1\n"
          ]
        }
      ],
      "source": [
        "! pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQJjLo2foHix",
        "outputId": "3adc5eec-e0f9-461b-dffd-3f001d30bb35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "120P53RZS_Cl"
      },
      "source": [
        "# 과제1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7zltQG3S_Cm"
      },
      "source": [
        "이탤릭체 텍스트- 의미를 포함할 수 있는 다양한 오픈소스 모델을 참고해서 문장을 임베딩하고, 왜 해당방법을 이용했는지 적어주세요.  아래 문장을 임베딩하는 과정을 기록해주시면 됩니다!\n",
        "“Do you admit it? I will not? You got so caught up in your anger that you turned off the internet. Admit it? I will not? “Don’t even watch TV!”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yrf78ZvmS_Cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aee5948-99c6-4bca-8e44-f07662baa79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.3529e-01, -1.5160e-02, -1.9171e-01, -2.6100e-01, -3.9825e-01,\n",
            "         -6.2848e-01,  8.0826e-01,  5.7124e-01, -2.4821e-01,  1.7000e-01,\n",
            "          3.2507e-01, -1.1956e-01, -2.3433e-01,  6.9934e-01,  4.6289e-01,\n",
            "          2.5571e-01, -6.6166e-02,  5.8675e-01,  1.0747e-01, -5.2528e-02,\n",
            "         -1.8045e-01, -3.3483e-01,  2.6617e-01, -1.3357e-01, -1.2528e-01,\n",
            "         -8.5998e-02, -3.8878e-02,  6.6421e-02, -1.1122e-03,  4.0183e-02,\n",
            "         -1.6294e-01,  4.0301e-02, -3.0829e-01, -2.1112e-01,  4.0208e-01,\n",
            "         -1.4520e-01, -1.2707e-02,  1.6095e-01,  6.1293e-02, -1.8428e-01,\n",
            "         -4.3805e-01,  1.0325e-01, -2.0169e-01,  1.7173e-01,  1.4504e-01,\n",
            "         -3.1536e-01, -2.8170e+00, -3.3517e-01, -2.7000e-02, -2.6165e-01,\n",
            "          2.7968e-01,  2.4183e-01, -8.3641e-02,  2.0644e-01,  1.0696e-01,\n",
            "          2.7784e-01, -4.2588e-01,  9.1014e-02, -7.6447e-02,  2.5291e-01,\n",
            "          3.7783e-01,  4.5681e-01, -2.0076e-01,  1.8921e-01,  1.2279e-01,\n",
            "         -1.8860e-02, -2.4620e-01,  5.0164e-01, -3.8024e-01,  3.0249e-01,\n",
            "         -5.0732e-01, -1.8707e-01, -7.8909e-03, -5.8170e-01,  1.9604e-01,\n",
            "         -2.5742e-01, -3.0040e-01,  2.1824e-01, -3.2952e-01,  1.4018e-01,\n",
            "         -2.0916e-02,  4.0328e-01,  8.7542e-02, -2.3804e-01,  2.3786e-01,\n",
            "          3.2906e-01, -3.7626e-01, -1.8748e-01,  4.3713e-01,  1.1342e-01,\n",
            "         -5.8214e-02,  4.8002e-01,  4.2414e-01,  5.5998e-01,  5.7625e-01,\n",
            "         -1.2784e-01,  1.0711e-01, -2.1138e-01,  1.6460e-01,  2.7121e-01,\n",
            "          2.2500e-01, -2.1363e-01,  2.9111e-01, -2.5596e-01,  1.7934e-01,\n",
            "          1.2953e-01,  8.3137e-02, -2.7740e-01,  4.6654e-01, -2.5262e+00,\n",
            "          2.9070e-01,  3.3010e-01, -4.3492e-01, -5.5671e-01, -3.6840e-01,\n",
            "          3.8081e-01,  1.0130e+00, -1.6385e-01,  4.6709e-01, -2.6187e-02,\n",
            "         -4.3761e-02, -1.3050e-01, -4.0695e-02, -2.3934e-02,  1.1045e-01,\n",
            "          3.6503e-01,  1.9747e-01, -2.3087e-01,  2.0218e-01,  2.3312e-01,\n",
            "          4.0063e-01,  6.3844e-01,  1.7166e-01, -3.1119e-01, -1.8915e-02,\n",
            "          2.0343e-01,  3.2145e-02, -3.4641e-01,  1.3261e-01, -5.4744e-01,\n",
            "         -6.0040e-01, -3.6537e-01, -3.0612e+00,  3.7183e-01,  4.9195e-01,\n",
            "          1.6712e-01, -1.9929e-01, -5.5074e-02,  4.4595e-02, -1.5980e-01,\n",
            "         -1.3063e-01,  5.5246e-02, -8.1708e-02, -8.0126e-02, -2.5812e-01,\n",
            "         -2.0921e-01, -1.8746e-01, -3.7342e-01,  4.8331e-01,  4.7749e-01,\n",
            "          6.5018e-01, -4.0000e-01,  4.4925e-03,  1.3641e-02, -6.2122e-01,\n",
            "          5.2850e-02,  7.8896e-02,  4.7886e-01, -7.6517e-02, -2.5226e-01,\n",
            "         -3.8039e-01,  1.7327e-01,  8.2351e-01,  3.3365e-01, -3.9938e-02,\n",
            "         -5.3708e-01,  1.7705e-01,  3.3723e-01,  1.7478e-01,  1.2266e-01,\n",
            "         -4.3975e-01,  3.7169e-01,  1.1759e-01,  4.2180e-02,  3.0326e-01,\n",
            "          4.1986e-01,  8.6522e-01, -1.9595e-01, -7.0264e-01,  5.2309e-01,\n",
            "          2.0614e-02, -4.8554e-01,  4.7011e-01,  5.2650e-01,  6.4328e-01,\n",
            "         -6.0843e-01,  1.3703e-01, -2.5297e-01,  4.1501e-01,  3.5498e-01,\n",
            "         -3.1366e-01, -1.6703e-01, -3.0769e-01, -1.2598e-01, -4.0756e-01,\n",
            "          4.2448e+00,  6.3423e-02, -3.2181e-01, -5.5321e-02,  2.3532e-01,\n",
            "         -5.7360e-01, -3.6699e-01,  1.7534e-01, -1.0166e-01, -6.1732e-01,\n",
            "          1.9147e-01,  2.3115e-01, -4.9796e-02, -1.4793e-01, -6.4713e-03,\n",
            "         -4.8286e-02, -2.0992e-02, -4.6508e-01,  1.0946e-02, -3.1891e-01,\n",
            "         -1.1211e-01, -2.1007e-01,  7.2795e-01,  1.5833e-01, -1.8620e+00,\n",
            "          1.5959e-01,  3.0121e-01, -4.5996e-01,  2.4386e-01, -1.1199e-01,\n",
            "         -1.8431e-01, -1.9003e-01,  6.5720e-02, -6.6738e-02, -3.5048e-02,\n",
            "          2.6268e-02,  3.7006e-01,  8.0927e-02,  1.3782e-01, -4.7350e-01,\n",
            "          4.3196e-01,  2.6856e-01,  2.9766e-01,  2.5909e-01, -3.3763e-02,\n",
            "          4.1086e-01, -2.3203e-01, -1.4541e-02, -5.1951e-02,  3.7082e-01,\n",
            "         -1.3952e-01,  2.0854e-01,  5.1765e-01, -4.0315e-01, -2.2108e-01,\n",
            "         -7.9848e-02, -1.1834e-01, -1.2513e-01,  4.3699e-01, -3.4701e-01,\n",
            "         -1.8566e-01,  4.5820e-01, -2.6349e-01, -2.6316e-01, -2.1295e-01,\n",
            "          7.5119e-02, -2.9387e-01, -4.7003e-01, -3.3050e+00,  1.7664e-01,\n",
            "          1.2033e-01, -1.7525e-02,  2.7792e-01, -3.1576e-01, -2.0604e-02,\n",
            "         -6.9207e-02,  3.1444e-01, -4.2668e-01,  5.5927e-01,  5.2436e-01,\n",
            "         -2.6410e-01,  6.8823e-01, -9.0230e-02,  3.3537e-01,  2.1891e-01,\n",
            "         -1.1071e-02, -7.9306e-02, -2.3349e-01, -1.7863e-01,  3.7757e-01,\n",
            "         -2.7758e-01,  4.5514e-01,  1.4102e-01, -3.6036e-02,  2.8623e-01,\n",
            "         -2.1516e-03,  4.0285e-01, -3.6903e-01,  1.8127e-01, -1.5036e-01,\n",
            "          5.0970e-02, -8.8895e-03, -6.5249e-01, -2.9224e+00,  1.0845e-01,\n",
            "         -3.6444e-01, -1.6782e-01, -3.0302e-02,  6.7653e-02,  1.0802e-01,\n",
            "         -1.7103e-01, -8.2041e-01,  1.8651e-01, -8.0737e-02, -4.3067e-01,\n",
            "         -1.0234e-02,  1.9746e-01,  4.0245e-02,  1.0860e-01,  6.3563e-01,\n",
            "         -5.0616e-01,  3.4004e-01,  2.6466e-01, -4.1281e-01,  1.8701e-01,\n",
            "          2.1377e-01,  2.9473e-02,  4.3326e-01,  6.9371e-01,  8.1857e-02,\n",
            "         -1.8315e-01,  1.5350e-01, -5.6513e-02, -2.5139e-01, -5.0770e-01,\n",
            "         -1.1008e-01,  1.4047e-01, -2.5288e-01, -3.1820e-01,  2.5154e-01,\n",
            "         -1.9054e-01, -9.9650e-02, -1.9360e-01,  4.7359e-01,  3.1702e-01,\n",
            "          2.2286e-01,  4.3373e-01,  7.5323e-01,  6.2171e-02, -8.9408e-03,\n",
            "         -1.5860e-01, -1.7258e-01, -1.3273e-01, -2.9568e-01,  1.1835e-02,\n",
            "          1.4176e+00, -1.6851e-01, -6.6644e-02, -1.3982e-01,  5.1092e-01,\n",
            "         -3.3693e-01,  1.0231e-01,  1.6009e-01,  4.8577e-01, -8.7757e-02,\n",
            "          1.5971e-02, -5.0934e-02, -3.3916e-02, -5.5167e-01,  6.6298e-02,\n",
            "         -8.4154e-01,  9.8421e-02, -7.8958e-02, -1.3511e-01,  1.6193e-01,\n",
            "         -3.0168e-01, -9.4976e-01, -3.6635e-01,  1.2234e-01, -1.7871e-01,\n",
            "          1.6889e-01,  2.7919e-02,  6.1557e-03, -3.6391e-01, -1.4763e-01,\n",
            "         -8.0197e-01,  3.0142e-01, -3.3798e-01, -5.5090e-01,  1.1910e-01,\n",
            "          4.0900e-01, -3.1785e-01,  8.9993e-02,  1.4333e-01,  3.3063e-01,\n",
            "          3.8327e-02,  6.2286e-01, -3.1982e-01,  4.9980e-01,  1.1284e-01,\n",
            "         -8.0689e-01,  2.7675e-01, -6.5219e-02, -3.5022e-01, -2.5061e-01,\n",
            "          2.3824e-01, -2.4941e-01, -7.4878e-02,  1.8328e-01, -4.1536e-01,\n",
            "          2.0407e-01, -9.8647e-02,  3.9933e-01, -2.9873e-01,  1.7717e-01,\n",
            "         -2.8486e-01,  3.8573e-01,  6.2736e-01,  9.0414e-02, -8.4362e-02,\n",
            "          5.4145e-01,  3.0238e-01,  3.5359e-02,  1.2842e-01,  1.5273e-01,\n",
            "         -3.9839e-01, -2.9626e-01, -1.4044e-01,  5.0929e-02,  2.0491e-01,\n",
            "         -4.0874e-01,  1.1577e-01, -3.2389e-01,  3.8788e-01, -2.9800e-01,\n",
            "         -6.7855e-01, -1.4134e-01,  2.2517e-01, -2.4564e-01, -6.4843e-02,\n",
            "          6.9705e-03,  8.3086e-03,  1.3837e-01,  2.5836e-01, -5.0837e-02,\n",
            "         -3.6851e-01,  2.3326e-01, -4.8858e-01,  5.4051e-01, -2.0337e-01,\n",
            "          1.8028e-01, -3.0813e-02,  7.0663e-01, -2.1145e-01, -5.9445e-01,\n",
            "         -7.3663e-02, -4.6523e-01, -3.3213e-02,  4.7780e-01, -1.0272e-01,\n",
            "          1.2898e-01,  1.9242e-01, -2.0099e-01, -4.0309e-02,  7.0813e-02,\n",
            "         -1.6869e+00,  2.3160e-01,  9.2289e-01,  4.8197e-02,  1.6100e-01,\n",
            "          2.2892e-02, -4.1152e-01,  5.0372e-01,  1.2505e-01,  2.0505e-01,\n",
            "         -2.0189e-01,  3.1505e-01,  2.4979e-01, -6.2166e-02,  2.7779e-01,\n",
            "          1.4730e-01,  1.6207e-01, -3.0085e-01, -3.4150e-01, -2.4989e-01,\n",
            "         -4.6018e-02,  3.3750e-01, -5.5990e-02, -1.6343e-01,  1.9162e-01,\n",
            "          7.3417e-03, -2.6144e-01,  5.9814e-01, -2.3809e-01,  4.0548e-01,\n",
            "          1.2639e-01, -3.7283e-01, -5.8262e-01, -2.4458e-01,  2.5253e-01,\n",
            "          7.3627e-02,  3.4020e-01,  3.6497e-01,  2.9937e-01,  6.9590e-01,\n",
            "         -2.5051e-01,  4.7944e-01,  3.6037e-01,  2.4748e-01,  2.8759e-01,\n",
            "          4.1001e-02, -1.5406e-01,  6.9532e-01,  1.1914e-01, -1.5040e-01,\n",
            "         -5.7509e-01, -1.8404e-01, -2.5277e-01, -4.0234e-01,  1.2846e-01,\n",
            "         -2.6317e-01,  2.0206e-01,  1.4292e-01, -3.1342e-01, -1.0260e-01,\n",
            "          2.0028e-01,  1.4610e-01, -4.5931e-01,  1.2474e-01, -1.8777e-01,\n",
            "         -5.3504e-01,  4.8420e-02, -4.6382e-01, -2.3190e-01,  4.4225e-01,\n",
            "          8.3177e-01,  3.5537e-01, -2.3351e-01, -3.4097e-02, -1.7102e-01,\n",
            "          3.4001e-01,  9.3874e-02,  5.8164e-01,  5.7686e-01, -5.0818e-01,\n",
            "          1.3563e-01, -1.4311e-01,  6.2830e-02,  3.6364e-01,  3.8232e-03,\n",
            "          1.6060e-01, -1.1337e-01, -4.9356e-01, -7.6195e-02, -3.0586e-01,\n",
            "         -6.8708e-01, -4.7694e-01,  1.4809e-01, -4.9326e-01,  1.2669e-01,\n",
            "          7.8635e-02,  2.5320e-01,  1.0278e-01,  2.2732e-03,  6.7738e-02,\n",
            "          8.9574e-02,  3.9468e-01,  4.4205e-01, -4.0673e-02,  3.8654e-01,\n",
            "          2.3469e-01,  2.9749e-01,  3.3646e-01, -4.3461e-01, -2.8581e-01,\n",
            "         -5.7781e-01, -1.9954e-01, -2.8076e-01, -1.9187e-01,  2.1142e-01,\n",
            "         -3.8252e-01,  3.3318e-01, -2.0845e-01,  2.0959e+00,  3.9779e-01,\n",
            "          9.0178e-02, -6.4667e-01,  2.7240e-01,  1.4920e-01, -7.4198e-02,\n",
            "          1.8091e-01, -2.8936e-01,  6.3596e-01, -5.1823e-01,  2.8154e-01,\n",
            "          3.4728e-01,  4.4656e-02,  9.1981e-01,  1.4140e-01,  2.2847e-02,\n",
            "         -3.9053e-01, -6.4277e-01, -2.5779e-01, -4.7014e-01,  2.3622e-01,\n",
            "          7.6106e-01, -4.5397e-03,  1.8415e-01,  2.1492e-01, -2.4924e-02,\n",
            "          5.4611e-02,  3.3068e-01,  5.3178e-01, -3.8506e-01,  8.1931e-02,\n",
            "          1.5957e-01,  3.2287e-01, -3.5207e-01,  4.9081e-01,  2.2495e-01,\n",
            "         -2.9023e-01, -2.6559e-01, -2.2069e-01, -3.3564e-02, -3.4546e-01,\n",
            "          3.9100e-01,  8.5394e-02, -7.9622e-02,  4.8867e-01, -3.2432e-01,\n",
            "         -2.2058e-01,  7.3551e-01,  1.3449e-01,  1.6550e-01,  2.2567e-01,\n",
            "         -3.9936e-01,  1.6823e-01,  6.8727e-03, -3.3444e-01, -5.2164e-02,\n",
            "         -5.9084e-02, -1.2682e-01,  1.6356e-01, -2.7606e-02,  4.6316e-01,\n",
            "          1.2409e-01, -2.6576e-01, -2.0158e-01,  5.9063e-01, -5.0679e-01,\n",
            "         -6.4713e-02,  9.0953e-02, -5.6621e-01, -5.8272e-02,  1.6963e-01,\n",
            "          4.1258e-01,  8.5957e-02,  3.6158e-01,  1.3755e-02,  3.0418e-01,\n",
            "         -4.6042e-01, -3.7105e-01, -2.9056e+00, -9.3474e-02,  5.6923e-02,\n",
            "         -2.0121e-01,  4.0935e-02,  2.2333e-01,  6.1914e-01, -1.7348e-01,\n",
            "          3.3952e-01,  3.5951e-02,  2.3784e-01,  2.9488e-01,  2.7829e-01,\n",
            "         -7.1113e-02,  5.9031e-04, -1.3690e-01,  3.9789e-01, -4.8038e-01,\n",
            "         -4.8821e-01, -3.2348e-01,  1.1482e-01,  1.7846e-03, -1.5799e-01,\n",
            "         -5.8202e-01, -3.8919e-01,  1.6385e-01,  2.5905e-01, -2.2905e-01,\n",
            "          6.9084e-02,  3.8717e-01, -4.3433e-02,  3.8578e-01, -1.9474e-01,\n",
            "         -1.3849e-01,  2.0641e-01, -4.2495e-02, -1.2483e-01, -3.1123e-01,\n",
            "          1.7889e-01,  9.7310e-02, -9.7068e-02,  5.7462e-01,  1.1383e-02,\n",
            "          2.0314e-01,  2.0139e-01, -5.3008e-01,  5.3765e-01, -9.0046e-02,\n",
            "          4.2498e-01, -6.7270e-01, -3.6317e-01, -8.6456e-02,  4.5856e-01,\n",
            "          1.7683e-01,  2.1737e-01,  1.9726e-01,  2.2761e-01,  4.1749e-01,\n",
            "          1.3623e-01, -3.7179e-01,  7.3795e-02, -3.5520e-02, -4.1835e-01,\n",
            "         -2.6472e-01,  2.3815e-01, -1.7753e-01,  9.8625e-02,  4.8414e-01,\n",
            "         -3.3863e-01, -3.7922e-01, -4.5940e-01, -2.0930e-01,  2.5730e-01,\n",
            "         -3.3332e-03,  2.0649e-01, -1.5009e-01,  2.6888e-01,  4.9242e-01,\n",
            "          2.3441e-01,  5.2560e-02, -3.4209e-01,  3.1120e-01,  9.0888e-02,\n",
            "          1.7958e-01,  2.8491e-01, -7.2227e+00,  1.2625e-01,  1.1208e-01,\n",
            "         -3.9911e-01,  1.6394e-01, -2.6923e-01,  1.6668e-01, -3.4308e-01,\n",
            "          6.1208e-02, -4.3733e-01,  4.0109e-02, -5.8066e-02, -5.9921e-02,\n",
            "         -3.0425e-01,  3.1791e-01,  3.9313e-01]])\n"
          ]
        }
      ],
      "source": [
        "###과제 1번###\n",
        "\n",
        "# BERT 사용: BERT는 각 단어 주변의 양방향 문맥을 고려하여, 의미를 잘 파악할 수 있기 때문이다.\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "text = \"Do you admit it? I will not? You got so caught up in your anger that you turned off the internet. Admit it? I will not? “Don’t even watch TV!\"\n",
        "\n",
        "inputs = tokenizer(text, return_tensors='pt', add_special_tokens=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "sentence_embedding = outputs.last_hidden_state[:, 0, :] #[CLS] 토큰의 출력 벡\n",
        "\n",
        "print(sentence_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skbX_4PYS_Cn"
      },
      "source": [
        "# 과제2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra8yUaZtS_Cn"
      },
      "source": [
        "두번째 과제는 1번에서 사용했던 문장 임베딩을 기반으로 유사도를 측정하는 것입니다. 데이터엔 제가 제일 좋아하는 노래 10곡을 넣어두었습니다.\n",
        "\n",
        "1. ipynb 파일을 완성해주세요.\n",
        "    1. 데이터의 노래들은 문장이 \\n으로 구분되어 있습니다.\n",
        "    2. \\n을 기준으로 간단히 전처리기를 만들어주세요!\n",
        "2. 완성 후 실행해본 다음 나온 노래를 들어보세요!\n",
        "\n",
        "3. 간단한 코멘트도 같이 달아주시면 좋습니다😉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds6ZxZiWCk1g",
        "outputId": "9eb5e401-2f6d-416c-8c01-fd9b3b68befe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how are you : I love her\n",
            "Artist: chet baker, Song: you’re mine, you!\n",
            "Artist: DeVita, Song: Bonnie & Clyde\n",
            "Artist: maroon5, Song: sugar\n",
            "Artist: taylor swift, Song: cruel_summer\n",
            "Artist: chet baker, Song: everything happens to me\n",
            "Artist: keane, Song: can't stop now\n",
            "Artist: coldplay, Song: stop crying your heart out\n",
            "Artist: AJR, Song: Karma\n",
            "Artist: keane, Song: everybody's changing\n",
            "Artist: wave to earth, Song: pueblo\n",
            "Artist: coldplay, Song: viva la vida\n"
          ]
        }
      ],
      "source": [
        "### 과제 2번 ###\n",
        "from typing import List, Union\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def cosine_similarity(vector1: np.ndarray, vector2: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    두 벡터의 코사인 유사도를 계산해주세요!\n",
        "    \"\"\"\n",
        "    ##################################################\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    norm_1 = np.linalg.norm(vector1)\n",
        "    norm_2 = np.linalg.norm(vector2)\n",
        "    return dot_product / (norm_1 * norm_2)\n",
        "\n",
        "    ##################################################\n",
        "\n",
        "def preprocess_lyrics(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    노래 가사를 줄 단위로 분할하는 전처리 함수를 완성해주세요!\n",
        "    \"\"\"\n",
        "    ##################################################\n",
        "\n",
        "    df['lyrics'] = df['lyrics'].str.strip('\\n')\n",
        "    return df\n",
        "\n",
        "    ##################################################\n",
        "\n",
        "def embed_lyrics(df: pd.DataFrame, model: SentenceTransformer) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    노래 가사를 임베딩해주세요!\n",
        "    \"\"\"\n",
        "    ##################################################\n",
        "\n",
        "    df['embedding'] = df['lyrics'].apply(lambda x: model.encode(x))\n",
        "    return df\n",
        "\n",
        "    ##################################################\n",
        "    pass\n",
        "\n",
        "def find_similar_song(df: pd.DataFrame, txt: str, model: SentenceTransformer) -> None:\n",
        "    \"\"\"\n",
        "    주어진 텍스트와 유사한 노래를 찾아 출력해주세요!\n",
        "    노래 가사 벡터의 평균 벡터 계산 & 유사도를 계산하기\n",
        "    \"\"\"\n",
        "    ##################################################\n",
        "\n",
        "    txt_embedding = model.encode(txt)\n",
        "\n",
        "    # 각 가사와의 코사인 유사도 계산\n",
        "    df['cosine_similarity'] = df['embedding'].apply(lambda x: cosine_similarity(x, txt_embedding))\n",
        "\n",
        "    ##################################################\n",
        "    # 코사인 유사도를 기준으로 데이터프레임 정렬\n",
        "    df_sorted = df.sort_values(by='cosine_similarity', ascending=False)\n",
        "\n",
        "    # 결과 출력\n",
        "    for idx, row in df_sorted.iterrows():\n",
        "        print(f\"Artist: {row['artist']}, Song: {row['song']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv('song_data.csv')\n",
        "    # Sentence Transformer 모델 초기화\n",
        "    model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')\n",
        "    # 데이터 전처리\n",
        "    df = preprocess_lyrics(df)\n",
        "    # 노래 가사 임베딩\n",
        "    df = embed_lyrics(df, model)\n",
        "    # 유사한 노래 찾기\n",
        "    txt = input('how are you : ')\n",
        "    find_similar_song(df, txt, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T_2KUPjOztD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}